{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: qwen2.5-coder:3b, Settings: {\"num_threads\": 1, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000}, Time: 25.96s\n",
      "Model: qwen2.5-coder:3b, Settings: {\"num_threads\": 2, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000}, Time: 21.04s\n",
      "Model: qwen2.5-coder:3b, Settings: {\"num_threads\": 4, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000}, Time: 25.52s\n",
      "Model: qwen2.5-coder:3b, Settings: {\"num_threads\": 8, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000}, Time: 19.53s\n",
      "Model: qwen2.5-coder:3b, Settings: {\"num_threads\": 1, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}, Time: 16.23s\n",
      "Model: qwen2.5-coder:3b, Settings: {\"num_threads\": 2, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}, Time: 12.75s\n",
      "Model: qwen2.5-coder:3b, Settings: {\"num_threads\": 4, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}, Time: 12.70s\n",
      "Model: qwen2.5-coder:3b, Settings: {\"num_threads\": 8, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}, Time: 14.00s\n",
      "Model: qwen2.5-coder:7b-instruct-q4_0, Settings: {\"num_threads\": 1, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000}, Time: 156.67s\n",
      "Model: qwen2.5-coder:7b-instruct-q4_0, Settings: {\"num_threads\": 2, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000}, Time: 131.54s\n",
      "Model: qwen2.5-coder:7b-instruct-q4_0, Settings: {\"num_threads\": 4, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000}, Time: 135.40s\n",
      "Model: qwen2.5-coder:7b-instruct-q4_0, Settings: {\"num_threads\": 8, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000}, Time: 126.47s\n",
      "Model: qwen2.5-coder:7b-instruct-q4_0, Settings: {\"num_threads\": 1, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}, Time: 128.38s\n",
      "Model: qwen2.5-coder:7b-instruct-q4_0, Settings: {\"num_threads\": 2, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}, Time: 129.36s\n",
      "Model: qwen2.5-coder:7b-instruct-q4_0, Settings: {\"num_threads\": 4, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}, Time: 128.84s\n",
      "Model: qwen2.5-coder:7b-instruct-q4_0, Settings: {\"num_threads\": 8, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}, Time: 130.17s\n",
      "\n",
      "Benchmark Results:\n",
      "Model: qwen2.5-coder:3b\n",
      "  Settings: {\"num_threads\": 1, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000}\n",
      "  Time Taken: 25.96 seconds\n",
      "  Output Length: 1418\n",
      "\n",
      "Model: qwen2.5-coder:3b\n",
      "  Settings: {\"num_threads\": 2, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000}\n",
      "  Time Taken: 21.04 seconds\n",
      "  Output Length: 1487\n",
      "\n",
      "Model: qwen2.5-coder:3b\n",
      "  Settings: {\"num_threads\": 4, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000}\n",
      "  Time Taken: 25.52 seconds\n",
      "  Output Length: 1487\n",
      "\n",
      "Model: qwen2.5-coder:3b\n",
      "  Settings: {\"num_threads\": 8, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000}\n",
      "  Time Taken: 19.53 seconds\n",
      "  Output Length: 1487\n",
      "\n",
      "Model: qwen2.5-coder:3b\n",
      "  Settings: {\"num_threads\": 1, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}\n",
      "  Time Taken: 16.23 seconds\n",
      "  Output Length: 1461\n",
      "\n",
      "Model: qwen2.5-coder:3b\n",
      "  Settings: {\"num_threads\": 2, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}\n",
      "  Time Taken: 12.75 seconds\n",
      "  Output Length: 1378\n",
      "\n",
      "Model: qwen2.5-coder:3b\n",
      "  Settings: {\"num_threads\": 4, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}\n",
      "  Time Taken: 12.70 seconds\n",
      "  Output Length: 1378\n",
      "\n",
      "Model: qwen2.5-coder:3b\n",
      "  Settings: {\"num_threads\": 8, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}\n",
      "  Time Taken: 14.00 seconds\n",
      "  Output Length: 1378\n",
      "\n",
      "Model: qwen2.5-coder:7b-instruct-q4_0\n",
      "  Settings: {\"num_threads\": 1, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000}\n",
      "  Time Taken: 156.67 seconds\n",
      "  Output Length: 2202\n",
      "\n",
      "Model: qwen2.5-coder:7b-instruct-q4_0\n",
      "  Settings: {\"num_threads\": 2, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000}\n",
      "  Time Taken: 131.54 seconds\n",
      "  Output Length: 1934\n",
      "\n",
      "Model: qwen2.5-coder:7b-instruct-q4_0\n",
      "  Settings: {\"num_threads\": 4, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000}\n",
      "  Time Taken: 135.40 seconds\n",
      "  Output Length: 1934\n",
      "\n",
      "Model: qwen2.5-coder:7b-instruct-q4_0\n",
      "  Settings: {\"num_threads\": 8, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000}\n",
      "  Time Taken: 126.47 seconds\n",
      "  Output Length: 1934\n",
      "\n",
      "Model: qwen2.5-coder:7b-instruct-q4_0\n",
      "  Settings: {\"num_threads\": 1, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}\n",
      "  Time Taken: 128.38 seconds\n",
      "  Output Length: 1950\n",
      "\n",
      "Model: qwen2.5-coder:7b-instruct-q4_0\n",
      "  Settings: {\"num_threads\": 2, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}\n",
      "  Time Taken: 129.36 seconds\n",
      "  Output Length: 1966\n",
      "\n",
      "Model: qwen2.5-coder:7b-instruct-q4_0\n",
      "  Settings: {\"num_threads\": 4, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}\n",
      "  Time Taken: 128.84 seconds\n",
      "  Output Length: 1966\n",
      "\n",
      "Model: qwen2.5-coder:7b-instruct-q4_0\n",
      "  Settings: {\"num_threads\": 8, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}\n",
      "  Time Taken: 130.17 seconds\n",
      "  Output Length: 1966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Define the models and settings to benchmark\n",
    "models = [\"qwen2.5-coder:3b\", \"qwen2.5-coder:7b-instruct-q4_0\"]  #\n",
    "settings = [\n",
    "    {\"num_threads\": 1, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000},\n",
    "    {\"num_threads\": 2, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000},\n",
    "    {\"num_threads\": 4, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000},\n",
    "    {\"num_threads\": 8, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 24000},\n",
    "    {\"num_threads\": 1, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000},\n",
    "    {\"num_threads\": 2, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000},\n",
    "    {\"num_threads\": 4, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000},\n",
    "    {\"num_threads\": 8, \"temperature\": 0.0, \"top_p\": 0.95, \"num_ctx\": 16000}\n",
    "]\n",
    "\n",
    "# Test prompt\n",
    "prompt = \"What is the meaning of life? Write 3 paragraphs on it.\"\n",
    "\n",
    "results = []\n",
    "\n",
    "for model in models:\n",
    "    for setting in settings:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Prepare the message for the model\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "            \n",
    "            # Make the API call with the current settings\n",
    "            response = ollama.chat(\n",
    "                model=model, \n",
    "                messages=messages, \n",
    "                options=setting\n",
    "            )\n",
    "            \n",
    "            # Calculate the time taken for the response\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            \n",
    "            # Store the results\n",
    "            results.append({\n",
    "                \"model\": model,\n",
    "                \"settings\": setting,\n",
    "                \"time_taken\": elapsed_time,\n",
    "                \"output_length\": len(response.message.content)  # Optional: measure response length\n",
    "            })\n",
    "            print(f\"Model: {model}, Settings: {json.dumps(setting)}, Time: {elapsed_time:.2f}s\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error with model {model} and settings {json.dumps(setting)}: {str(e)}\")\n",
    "\n",
    "# Output results\n",
    "print(\"\\nBenchmark Results:\")\n",
    "for result in results:\n",
    "    print(f\"Model: {result['model']}\")\n",
    "    print(f\"  Settings: {json.dumps(result['settings'])}\")\n",
    "    print(f\"  Time Taken: {result['time_taken']:.2f} seconds\")\n",
    "    print(f\"  Output Length: {result['output_length']}\")\n",
    "    print()\n",
    "\n",
    "# Optionally, you could write these results to a CSV or JSON file for further analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
